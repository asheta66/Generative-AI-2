{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD+u0JqqnwGovEmHekNggr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/Generative-AI-2/blob/main/Classification_using_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmX20x5HmcpK"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Set the directory for the data stored on Google Drive\n",
        "data_dir = '/content/drive/My Drive/data2'\n",
        "\n",
        "# Define image size and batch size for data generators\n",
        "img_size = (128, 128)  # Adjust according to your data\n",
        "batch_size = 32\n",
        "\n",
        "# Set up data generators for training and validation with 20% validation split\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = datagen.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', subset='training')\n",
        "val_generator = datagen.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='categorical', subset='validation')\n",
        "\n",
        "# Determine the number of classes from the data generator\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "# Define the Autoencoder model structure\n",
        "input_img = Input(shape=(img_size[0], img_size[1], 3))\n",
        "\n",
        "# Encoder part\n",
        "x = Flatten()(input_img)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "encoded = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Decoder part\n",
        "x = Dense(128, activation='relu')(encoded)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(img_size[0] * img_size[1] * 3, activation='sigmoid')(x)\n",
        "decoded = Reshape((img_size[0], img_size[1], 3))(x)\n",
        "\n",
        "# Compile the Autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Print the summary of the Autoencoder model\n",
        "autoencoder.summary()\n",
        "\n",
        "# Train the Autoencoder model\n",
        "history = autoencoder.fit(train_generator, epochs=50, validation_data=val_generator)\n",
        "\n",
        "# Extract the encoder part of the Autoencoder for feature extraction\n",
        "encoder = Model(inputs=input_img, outputs=encoded)\n",
        "\n",
        "# Define the classification model using the encoded features\n",
        "encoded_input = Input(shape=(64,))\n",
        "x = Dense(64, activation='relu')(encoded_input)\n",
        "x = Dense(num_classes, activation='softmax')(x)\n",
        "classifier = Model(inputs=encoded_input, outputs=x)\n",
        "\n",
        "# Compile the classifier model with categorical crossentropy loss\n",
        "classifier.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "classifier.summary()\n",
        "\n",
        "# Generate encoded features for training and validation data\n",
        "train_features = encoder.predict(train_generator)\n",
        "val_features = encoder.predict(val_generator)\n",
        "\n",
        "# Get the corresponding labels and convert them to one-hot encoding\n",
        "train_labels = train_generator.classes\n",
        "val_labels = val_generator.classes\n",
        "\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels = to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "# Train the classifier model using the encoded features\n",
        "history_classifier = classifier.fit(train_features, train_labels, epochs=50, validation_data=(val_features, val_labels))\n",
        "\n",
        "# Evaluate the classifier using the validation data\n",
        "val_predictions = np.argmax(classifier.predict(val_features), axis=1)\n",
        "\n",
        "# Create and display the confusion matrix\n",
        "conf_matrix = confusion_matrix(val_generator.classes, val_predictions)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report for precision, recall, and F1-score\n",
        "print(classification_report(val_generator.classes, val_predictions, target_names=val_generator.class_indices.keys()))\n",
        "\n",
        "# Plot the training and validation loss curves for the Autoencoder\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Autoencoder Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation accuracy curves for the classifier\n",
        "plt.plot(history_classifier.history['accuracy'], label='train_acc')\n",
        "plt.plot(history_classifier.history['val_accuracy'], label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Classifier Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ]
}