{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeZTzLKbdUw3KCjHfKgPWi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/Generative-AI-2/blob/main/B_Class_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "Onyav4nNX5pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install latex\n",
        "# !sudo apt-get update -y\n",
        "# !sudo apt-get install -y texlive texlive-latex-extra texlive-fonts-recommended dvipng cm-super"
      ],
      "metadata": {
        "id": "gbBG6ojEcQKs"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y pandas tensorflow\n",
        "# !pip install pandas tensorflow\n",
        "# !pip install seaborn"
      ],
      "metadata": {
        "id": "Jbp4IrMOdoPc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Function to get the size of the first image in the directory\n",
        "def get_image_size(data_dir):\n",
        "    # List all files in the directory\n",
        "    files = [f for f in os.listdir(data_dir) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    # Check if there are any image files in the directory\n",
        "    if not files:\n",
        "        raise FileNotFoundError(\"No image files found in the directory.\")\n",
        "\n",
        "    # Load the first image to determine its size\n",
        "    first_image_path = os.path.join(data_dir, files[0])\n",
        "    with Image.open(first_image_path) as img:\n",
        "        return img.size  # Returns (width, height)\n",
        "\n",
        "# Set the directory for the data stored on Google Drive\n",
        "data_dir = '/content/drive/My Drive/BrainTumor/256x256'\n",
        "\n",
        "# Automatically determine image size\n",
        "try:\n",
        "    img_size = get_image_size(data_dir)\n",
        "    batch_size = 32\n",
        "    print(f\"Image size set to: {img_size}\")\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n",
        "\n",
        "# Set up data generators for training and validation with 20% validation split\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = datagen.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='input', subset='training')\n",
        "val_generator = datagen.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='input', subset='validation')\n",
        "\n",
        "# Determine the number of classes from the data generator\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "print(\"\")\n",
        "# Display the names of the classes and the number of images in each class\n",
        "print(\"Class Names and Number of Images:\")\n",
        "print(\"\")\n",
        "for class_name, index in train_generator.class_indices.items():\n",
        "    num_images = len(os.listdir(os.path.join(data_dir, class_name)))\n",
        "    print(f\"{class_name}: {num_images} images\")\n",
        "print(\"\")\n"
      ],
      "metadata": {
        "id": "dJ4lacVqXwt8",
        "outputId": "62f78ce2-c291-4b9f-e658-021450383458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "No image files found in the directory.\n",
            "Found 2452 images belonging to 3 classes.\n",
            "Found 612 images belonging to 3 classes.\n",
            "\n",
            "Class Names and Number of Images:\n",
            "\n",
            "glioma: 1426 images\n",
            "meningioma: 708 images\n",
            "pituitary tumor: 930 images\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Autoencoder model structure**"
      ],
      "metadata": {
        "id": "HzUrMTfDX2Fd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qze3-dKsIY4x",
        "outputId": "66a50390-2801-4461-aac9-d132ea26fcd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1052s\u001b[0m 13s/step - loss: 0.0218 - val_loss: 0.0068\n",
            "Epoch 2/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 2s/step - loss: 0.0069 - val_loss: 0.0061\n",
            "Epoch 3/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - loss: 0.0062 - val_loss: 0.0056\n",
            "Epoch 4/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - loss: 0.0059 - val_loss: 0.0054\n",
            "Epoch 5/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - loss: 0.0056 - val_loss: 0.0052\n",
            "Epoch 6/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 2s/step - loss: 0.0053 - val_loss: 0.0051\n",
            "Epoch 7/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 2s/step - loss: 0.0051 - val_loss: 0.0050\n",
            "Epoch 8/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 2s/step - loss: 0.0049 - val_loss: 0.0049\n",
            "Epoch 9/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 3s/step - loss: 0.0048 - val_loss: 0.0048\n",
            "Epoch 10/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 2s/step - loss: 0.0047 - val_loss: 0.0049\n",
            "Epoch 11/20\n",
            "\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 2s/step - loss: 0.0046 - val_loss: 0.0047\n",
            "Epoch 12/20\n",
            "\u001b[1m10/77\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:28\u001b[0m 2s/step - loss: 0.0044"
          ]
        }
      ],
      "source": [
        "# Define the Autoencoder model structure\n",
        "input_img = Input(shape=(img_size[0], img_size[1], 3))\n",
        "\n",
        "# Encoder part\n",
        "x = Flatten()(input_img)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "encoded = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Decoder part\n",
        "x = Dense(128, activation='relu')(encoded)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(img_size[0] * img_size[1] * 3, activation='sigmoid')(x)\n",
        "decoded = Reshape((img_size[0], img_size[1], 3))(x)\n",
        "\n",
        "# Compile the Autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the Autoencoder model\n",
        "history = autoencoder.fit(train_generator, epochs=10, validation_data=val_generator)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the encoder part of the Autoencoder for feature extraction and  build a classifier **"
      ],
      "metadata": {
        "id": "O-BS2abd6Sic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the encoder part of the Autoencoder for feature extraction\n",
        "encoder = Model(inputs=input_img, outputs=encoded)\n",
        "\n",
        "# Define the classification model using the encoded features\n",
        "encoded_input = Input(shape=(64,))\n",
        "x = Dense(64, activation='relu')(encoded_input)\n",
        "x = Dense(num_classes, activation='softmax')(x)\n",
        "classifier = Model(inputs=encoded_input, outputs=x)\n",
        "\n",
        "# Compile the classifier model with categorical crossentropy loss\n",
        "classifier.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "classifier.summary()\n",
        "\n",
        "# Generate encoded features for training and validation data\n",
        "train_features = encoder.predict(train_generator)\n",
        "val_features = encoder.predict(val_generator)\n",
        "\n",
        "# Get the corresponding labels and convert them to one-hot encoding\n",
        "train_labels = train_generator.classes\n",
        "val_labels = val_generator.classes\n",
        "\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels = to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "# Train the classifier model using the encoded features\n",
        "history_classifier = classifier.fit(train_features, train_labels, epochs=50, validation_data=(val_features, val_labels))\n",
        "\n",
        "# Evaluate the classifier using the training data\n",
        "train_predictions = np.argmax(classifier.predict(train_features), axis=1)\n",
        "train_labels_original = np.argmax(train_labels, axis=1)\n",
        "\n",
        "# Evaluate the classifier using the validation data\n",
        "val_predictions = np.argmax(classifier.predict(val_features), axis=1)\n",
        "val_labels_original = np.argmax(val_labels, axis=1)"
      ],
      "metadata": {
        "id": "Za72o_HD6Q-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Results**"
      ],
      "metadata": {
        "id": "gn-cyp1rX-m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display confusion matrices and classification reports\n",
        "conf_matrix_train = confusion_matrix(train_labels_original, train_predictions)\n",
        "conf_matrix_val = confusion_matrix(val_labels_original, val_predictions)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "\n",
        "# Plot training confusion matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap='Blues',\n",
        "            xticklabels=train_generator.class_indices.keys(),\n",
        "            yticklabels=train_generator.class_indices.keys(),\n",
        "            annot_kws={\"size\": 10, \"weight\": \"bold\"})  # Annotation properties\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Training Confusion Matrix')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels\n",
        "plt.yticks(rotation=45, ha='right')  # Rotate y-axis labels\n",
        "\n",
        "# Plot validation confusion matrix\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(conf_matrix_val, annot=True, fmt=\"d\", cmap='Blues',\n",
        "            xticklabels=val_generator.class_indices.keys(),\n",
        "            yticklabels=val_generator.class_indices.keys(),\n",
        "            annot_kws={\"size\": 10, \"weight\": \"bold\"})  # Annotation properties\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Validation Confusion Matrix')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels\n",
        "plt.yticks(rotation=45, ha='right')  # Rotate y-axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure to a file\n",
        "plt.savefig('/content/confusion_matrices.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qEJhDO2oa6Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Print classification reports\n",
        "# print(\"Training Classification Report:\")\n",
        "# print(classification_report(train_labels_original, train_predictions, target_names=train_generator.class_indices.keys()))\n",
        "\n",
        "# print(\"Validation Classification Report:\")\n",
        "# print(classification_report(val_labels_original, val_predictions, target_names=val_generator.class_indices.keys()))\n",
        "\n",
        "# Plot Training and Validation Loss for Autoencoder and Classifier Accuracy\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Autoencoder Loss Curves\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Autoencoder Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Classifier Accuracy Curves\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_classifier.history['accuracy'], label='train_acc')\n",
        "plt.plot(history_classifier.history['val_accuracy'], label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Classifier Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UD00ltiwT6dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Plot 6 random images (1 from each class) in a 2x3 grid\n",
        "plt.figure(figsize=(6, 4))\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "num_samples_per_class = 1  # Select 1 random image per class\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    # Fetch a batch of images for the current class\n",
        "    class_images, _ = next(datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=100,  # Ensure batch size is large enough to include random images\n",
        "        class_mode='input',\n",
        "        subset='training',\n",
        "        shuffle=True,\n",
        "        classes=[class_name]\n",
        "    ))\n",
        "\n",
        "    # Select a random image from the batch\n",
        "    random_index = np.random.randint(0, class_images.shape[0])\n",
        "    image = class_images[random_index]\n",
        "\n",
        "    # Plot the random image\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(class_name)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n_0TJVVmayub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}