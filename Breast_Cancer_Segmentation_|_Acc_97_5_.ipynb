{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2021025,
          "sourceType": "datasetVersion",
          "datasetId": 1209633
        }
      ],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Breast Cancer Segmentation | Acc: 97.5% ",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/Generative-AI-2/blob/main/Breast_Cancer_Segmentation_%7C_Acc_97_5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'breast-ultrasound-images-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1209633%2F2021025%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240829%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240829T223014Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D8abf9b2cd50108698daa2fd62e9aa05f527835255356afa9a2bacf7e4fbfae48b2e8ad2d04e27e3c77f972b178558dfcbfbfc1a7d80f8bc4a3f4a274d4806a6271fd8bb30657175b4c69227356a944fcc6e9dfabe1edd7154b8231fb147b3efe072490f3a4bcd62575edcff00810245a5b63735b317a006483d99a22ba234cc41632ef9922633e14062a4dedf2e8f08d174cc14eb4296ea46d8c31a7bc362e5cef2f3408c3c83276872633edbb4e9306f6a049695c71fa0e57620fcd094f579847534906c72b652e74bf8910e6bf88829830735c48085128d23a71cd0d0101521c980c86a42f614697d6929ca809630edb6e47e78c0d6a8631e77796c2493295'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "uzzrTa-uQ7LX",
        "outputId": "b29f5305-b21c-4195-b8e8-209baf3c3c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading breast-ultrasound-images-dataset, 204421470 bytes compressed\n",
            "[==================================================] 204421470 bytes downloaded"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3c259c55a1f3>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m               \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mzfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m               \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1712\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m             self._eof = (self._decompressor.eof or\n\u001b[1;32m   1007\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard Libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Scikit-learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Keras\n",
        "from keras import Sequential, Model\n",
        "from keras.layers import (Input, Conv2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, MaxPooling2D,AveragePooling2D, Dropout, Dense, Flatten)\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:03:20.016689Z",
          "iopub.execute_input": "2024-08-12T18:03:20.017606Z",
          "iopub.status.idle": "2024-08-12T18:03:33.680388Z",
          "shell.execute_reply.started": "2024-08-12T18:03:20.017568Z",
          "shell.execute_reply": "2024-08-12T18:03:33.679517Z"
        },
        "trusted": true,
        "id": "lQ0JH3kYQ7LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Objects to hold pairs of images and masks\n",
        "train_image_mask = {\n",
        "    'images': [],\n",
        "    'masks': []\n",
        "}\n",
        "\n",
        "test_image_mask = {\n",
        "    'images': [],\n",
        "    'masks': []\n",
        "}\n",
        "\n",
        "# Objects to hold pairs of images and labels\n",
        "train_image_class = {\n",
        "    'images': [],\n",
        "    'labels': []\n",
        "}\n",
        "\n",
        "test_image_class = {\n",
        "    'images': [],\n",
        "    'labels': []\n",
        "}\n",
        "\n",
        "def load_image_mask(train_image_mask=None, test_image_mask=None, image_path=None, shape=256):\n",
        "    \"\"\"Generates image/mask pairs from the dataset.\n",
        "\n",
        "    Args:\n",
        "        train_image_mask (dict): Dictionary to store training images and masks.\n",
        "        test_image_mask (dict): Dictionary to store testing images and masks.\n",
        "        image_path (str): Path to the images and masks.\n",
        "        shape (int): Size to resize images and masks.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Updated dictionaries containing images and masks.\n",
        "    \"\"\"\n",
        "    file_names = os.listdir(image_path)\n",
        "\n",
        "    image_names = []\n",
        "    mask_names = []\n",
        "    partial_names = [fn.split(')')[0] for fn in file_names]\n",
        "\n",
        "    partial_names = list(set(partial_names))\n",
        "\n",
        "    for name in partial_names:\n",
        "        image_names.append(name + ').png')\n",
        "        mask_names.append(name + ')_mask.png')\n",
        "\n",
        "    train_test_split_index = int(len(image_names) * 0.8)\n",
        "\n",
        "    for i, image_name in enumerate(image_names):\n",
        "        image = plt.imread(os.path.join(image_path, image_name))\n",
        "        mask = plt.imread(os.path.join(image_path, mask_names[i]))\n",
        "\n",
        "        image = cv2.resize(image, (shape, shape))\n",
        "        mask = cv2.resize(mask, (shape, shape))\n",
        "\n",
        "        if i < train_test_split_index:\n",
        "            train_image_mask['images'].append(image)\n",
        "            train_image_mask['masks'].append(mask)\n",
        "        else:\n",
        "            test_image_mask['images'].append(image)\n",
        "            test_image_mask['masks'].append(mask)\n",
        "\n",
        "    return train_image_mask, test_image_mask\n",
        "\n",
        "def load_image_class(train_image_class=None, test_image_class=None, image_path=None, shape=256):\n",
        "    \"\"\"Generates image/label pairs from the dataset.\n",
        "\n",
        "    Args:\n",
        "        train_image_class (dict): Dictionary to store training images and labels.\n",
        "        test_image_class (dict): Dictionary to store testing images and labels.\n",
        "        image_path (str): Path to the images.\n",
        "        shape (int): Size to resize images.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Updated dictionaries containing images and labels.\n",
        "    \"\"\"\n",
        "    file_names = os.listdir(image_path)\n",
        "    image_class = os.path.basename(image_path)\n",
        "\n",
        "    image_names = [fn.split(')')[0] + ').png' for fn in file_names]\n",
        "\n",
        "    train_test_split_index = int(len(image_names) * 0.8)\n",
        "\n",
        "    for i, image_name in enumerate(image_names):\n",
        "        image = plt.imread(os.path.join(image_path, image_name))\n",
        "        image = cv2.resize(image, (shape, shape))\n",
        "\n",
        "        if i < train_test_split_index:\n",
        "            train_image_class['images'].append(image)\n",
        "            train_image_class['labels'].append(image_class)\n",
        "        else:\n",
        "            test_image_class['images'].append(image)\n",
        "            test_image_class['labels'].append(image_class)\n",
        "\n",
        "    return train_image_class, test_image_class"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:03:33.681978Z",
          "iopub.execute_input": "2024-08-12T18:03:33.682543Z",
          "iopub.status.idle": "2024-08-12T18:03:33.697851Z",
          "shell.execute_reply.started": "2024-08-12T18:03:33.682515Z",
          "shell.execute_reply": "2024-08-12T18:03:33.696787Z"
        },
        "trusted": true,
        "id": "u5rJTVZwQ7Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "base_dir = Path(\"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT\")\n",
        "categories = ['normal', 'benign', 'malignant']\n",
        "\n",
        "for category in categories:\n",
        "    image_dir = base_dir / category / 'images'\n",
        "    mask_dir = base_dir / category / 'masks'\n",
        "\n",
        "    print(f\"Checking directories for category '{category}':\")\n",
        "    print(f\"Images directory: {image_dir}\")\n",
        "    print(f\"Masks directory: {mask_dir}\")\n",
        "\n",
        "    if image_dir.exists():\n",
        "        print(\"Images directory exists.\")\n",
        "        print(list(image_dir.iterdir()))  # List files in the images directory\n",
        "    else:\n",
        "        print(f\"Error: Images directory {image_dir} does not exist.\")\n",
        "\n",
        "    if mask_dir.exists():\n",
        "        print(\"Masks directory exists.\")\n",
        "        print(list(mask_dir.iterdir()))  # List files in the masks directory\n",
        "    else:\n",
        "        print(f\"Error: Masks directory {mask_dir} does not exist.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:03:33.69964Z",
          "iopub.execute_input": "2024-08-12T18:03:33.700376Z",
          "iopub.status.idle": "2024-08-12T18:03:33.746415Z",
          "shell.execute_reply.started": "2024-08-12T18:03:33.700342Z",
          "shell.execute_reply": "2024-08-12T18:03:33.745499Z"
        },
        "trusted": true,
        "id": "9YMro5tdQ7Lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Benign class images and masks\n",
        "train_image_mask, test_image_mask = load_image_mask(\n",
        "    train_image_mask=train_image_mask,\n",
        "    test_image_mask=test_image_mask,\n",
        "    image_path=\"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign\"\n",
        ")\n",
        "\n",
        "train_image_class, test_image_class = load_image_class(\n",
        "    train_image_class=train_image_class,\n",
        "    test_image_class=test_image_class,\n",
        "    image_path=\"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign\"\n",
        ")\n",
        "\n",
        "# Load Malignant class images and masks\n",
        "train_image_mask, test_image_mask = load_image_mask(\n",
        "    train_image_mask=train_image_mask,\n",
        "    test_image_mask=test_image_mask,\n",
        "    image_path=\"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant\"\n",
        ")\n",
        "\n",
        "train_image_class, test_image_class = load_image_class(\n",
        "    train_image_class=train_image_class,\n",
        "    test_image_class=test_image_class,\n",
        "    image_path=\"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/malignant\"\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:03:33.748711Z",
          "iopub.execute_input": "2024-08-12T18:03:33.748997Z",
          "iopub.status.idle": "2024-08-12T18:04:04.240213Z",
          "shell.execute_reply.started": "2024-08-12T18:03:33.748972Z",
          "shell.execute_reply": "2024-08-12T18:04:04.239163Z"
        },
        "trusted": true,
        "id": "_1o8c8p9Q7Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display one image/mask pair from the loaded dataset\n",
        "plt.figure(figsize=(8, 3))\n",
        "\n",
        "# Display the ultrasound image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(train_image_mask['images'][0])\n",
        "plt.title('Ultrasound Image')\n",
        "\n",
        "# Display the corresponding mask\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(train_image_mask['masks'][0], cmap='plasma')\n",
        "plt.title('Mask')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:04:04.241529Z",
          "iopub.execute_input": "2024-08-12T18:04:04.24186Z",
          "iopub.status.idle": "2024-08-12T18:04:05.00158Z",
          "shell.execute_reply.started": "2024-08-12T18:04:04.241823Z",
          "shell.execute_reply": "2024-08-12T18:04:05.000596Z"
        },
        "trusted": true,
        "id": "xuZj1NChQ7Lc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of one Convolution block of the U-Net architecture\n",
        "def convolutionBlock(inputTensor, filterCount, kernelSize = 3):\n",
        "    convolutionBlock = Conv2D(filters = filterCount, kernel_size = (kernelSize, kernelSize), kernel_initializer = 'he_normal', padding = 'same')(inputTensor)\n",
        "    convolutionBlock = BatchNormalization()(convolutionBlock)\n",
        "    convolutionBlock = Activation('relu')(convolutionBlock)\n",
        "\n",
        "    convolutionBlock = Conv2D(filters = filterCount, kernel_size = (kernelSize, kernelSize), kernel_initializer = 'he_normal', padding = 'same')(convolutionBlock)\n",
        "    convolutionBlock = BatchNormalization()(convolutionBlock)\n",
        "    convolutionBlock = Activation('relu')(convolutionBlock)\n",
        "\n",
        "    return convolutionBlock\n",
        "\n",
        "# Definition of the entire U-Net architecture\n",
        "def modelArchitecture(inputTensor, filterCount = 16, dropoutRate = 0.1):\n",
        "    # Initialization of the encoder\n",
        "    firstConvolution = convolutionBlock(inputTensor, filterCount)\n",
        "    firstLayer = AveragePooling2D((2, 2))(firstConvolution)\n",
        "    firstLayer = Dropout(dropoutRate)(firstLayer)\n",
        "\n",
        "    secondConvolution = convolutionBlock(firstLayer, filterCount * 2)\n",
        "    secondLayer = AveragePooling2D((2, 2))(secondConvolution)\n",
        "    secondLayer = Dropout(dropoutRate)(secondLayer)\n",
        "\n",
        "    thirdConvolution = convolutionBlock(secondLayer, filterCount * 4)\n",
        "    thirdLayer = AveragePooling2D((2, 2))(thirdConvolution)\n",
        "    thirdLayer = Dropout(dropoutRate)(thirdLayer)\n",
        "\n",
        "    fourthConvolution = convolutionBlock(thirdLayer, filterCount * 8)\n",
        "    fourthLayer = AveragePooling2D((2, 2))(fourthConvolution)\n",
        "    fourthLayer = Dropout(dropoutRate)(fourthLayer)\n",
        "\n",
        "    fifthConvolution = convolutionBlock(fourthLayer, filterCount * 16)\n",
        "\n",
        "    # Initialization of the decoder\n",
        "    firstDeconvolution = Conv2DTranspose(filterCount * 8, (3, 3), strides = (2, 2), padding = 'same')(fifthConvolution)\n",
        "    sixthLayer = concatenate([firstDeconvolution, fourthConvolution])\n",
        "    sixthLayer = Dropout(dropoutRate)(sixthLayer)\n",
        "    sixthConvolution = convolutionBlock(sixthLayer, filterCount * 8)\n",
        "\n",
        "    secondDeconvolution = Conv2DTranspose(filterCount * 4, (3, 3), strides = (2, 2), padding = 'same')(sixthConvolution)\n",
        "    seventhLayer = concatenate([secondDeconvolution, thirdConvolution])\n",
        "    seventhLayer = Dropout(dropoutRate)(seventhLayer)\n",
        "    seventhConvolution = convolutionBlock(seventhLayer, filterCount * 4)\n",
        "\n",
        "    thirdDeconvolution = Conv2DTranspose(filterCount * 2, (3, 3), strides = (2, 2), padding = 'same')(seventhConvolution)\n",
        "    eighthLayer = concatenate([thirdDeconvolution, secondConvolution])\n",
        "    eighthLayer = Dropout(dropoutRate)(eighthLayer)\n",
        "    eighthConvolution = convolutionBlock(eighthLayer, filterCount * 2)\n",
        "\n",
        "    fourthDeconvolution = Conv2DTranspose(filterCount, (3, 3), strides = (2, 2), padding = 'same')(eighthConvolution)\n",
        "    ninthLayer = concatenate([fourthDeconvolution, firstConvolution])\n",
        "    ninthLayer = Dropout(dropoutRate)(ninthLayer)\n",
        "    ninthConvolution = convolutionBlock(ninthLayer, filterCount)\n",
        "\n",
        "    outputLayer = Conv2D(1, (1, 1), activation = 'sigmoid')(ninthConvolution)\n",
        "    segmentationModel = Model(inputs = [inputTensor], outputs = [outputLayer])\n",
        "\n",
        "    return segmentationModel"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:04:05.002801Z",
          "iopub.execute_input": "2024-08-12T18:04:05.003088Z",
          "iopub.status.idle": "2024-08-12T18:04:05.023313Z",
          "shell.execute_reply.started": "2024-08-12T18:04:05.003063Z",
          "shell.execute_reply": "2024-08-12T18:04:05.022499Z"
        },
        "trusted": true,
        "id": "vIP95lTqQ7Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialization of the segmentation model\n",
        "inputs = Input((256, 256, 3))\n",
        "\n",
        "segmentationModel = modelArchitecture(inputs, dropoutRate = 0.1)\n",
        "segmentationModel.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "segmentationModel.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:04:05.02481Z",
          "iopub.execute_input": "2024-08-12T18:04:05.025154Z",
          "iopub.status.idle": "2024-08-12T18:04:06.182699Z",
          "shell.execute_reply.started": "2024-08-12T18:04:05.025106Z",
          "shell.execute_reply": "2024-08-12T18:04:06.181748Z"
        },
        "trusted": true,
        "id": "FqO9qocSQ7Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = segmentationModel.fit(\n",
        "    np.array(train_image_mask['images']),\n",
        "    np.array(train_image_mask['masks']),\n",
        "    epochs=15,\n",
        "    validation_data=(\n",
        "        np.array(test_image_mask['images']),\n",
        "        np.array(test_image_mask['masks'])\n",
        "    ),\n",
        "    callbacks=[\n",
        "        EarlyStopping(\n",
        "            patience=15,\n",
        "            monitor='val_loss',\n",
        "            mode='min',\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:04:06.183854Z",
          "iopub.execute_input": "2024-08-12T18:04:06.184159Z",
          "iopub.status.idle": "2024-08-12T18:08:52.217044Z",
          "shell.execute_reply.started": "2024-08-12T18:04:06.184115Z",
          "shell.execute_reply": "2024-08-12T18:08:52.216208Z"
        },
        "trusted": true,
        "id": "noZbiULoQ7Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "accuracy = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs = range(len(accuracy))\n",
        "\n",
        "# Convert accuracy and loss to a DataFrame for easier plotting with Seaborn\n",
        "history_df = pd.DataFrame({\n",
        "    'Epoch': epochs,\n",
        "    'Accuracy': accuracy,\n",
        "    'Loss': loss\n",
        "})\n",
        "\n",
        "# Create subplots to place the plots side by side\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 5))\n",
        "\n",
        "# Plot training accuracy using Seaborn\n",
        "sns.lineplot(data=history_df, x='Epoch', y='Accuracy', ax=axes[0])\n",
        "axes[0].set_title('Training Accuracy')\n",
        "\n",
        "# Plot training loss using Seaborn\n",
        "sns.lineplot(data=history_df, x='Epoch', y='Loss', ax=axes[1])\n",
        "axes[1].set_title('Training Loss')\n",
        "\n",
        "# Display the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:15:18.285734Z",
          "iopub.execute_input": "2024-08-12T18:15:18.286098Z",
          "iopub.status.idle": "2024-08-12T18:15:18.911891Z",
          "shell.execute_reply.started": "2024-08-12T18:15:18.286066Z",
          "shell.execute_reply": "2024-08-12T18:15:18.910952Z"
        },
        "trusted": true,
        "id": "I0KEMjDYQ7Lf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testImages = test_image_mask['images']\n",
        "testMasks = test_image_mask['masks']\n",
        "\n",
        "predictions = segmentationModel.predict(np.array(testImages))\n",
        "print(predictions.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:15:23.252532Z",
          "iopub.execute_input": "2024-08-12T18:15:23.253179Z",
          "iopub.status.idle": "2024-08-12T18:15:26.587927Z",
          "shell.execute_reply.started": "2024-08-12T18:15:23.253148Z",
          "shell.execute_reply": "2024-08-12T18:15:26.586966Z"
        },
        "trusted": true,
        "id": "4S91scQ2Q7Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the indices for the images you want to plot\n",
        "indices = [56, 90, 80]  # Modify these indices as needed\n",
        "\n",
        "# Initialize the figure with a 3x3 grid\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# Loop over the indices and create subplots\n",
        "for i, idx in enumerate(indices):\n",
        "    # Determine the row and column for each image\n",
        "    row = i // 3  # Row index (0 for the first row, 1 for the second row, etc.)\n",
        "    col = i % 3   # Column index (0 for the first column, 1 for the second column, etc.)\n",
        "\n",
        "    # Plot Ultrasound Image\n",
        "    plt.subplot(3, 3, 3*i + 1)\n",
        "    plt.imshow(testImages[idx])\n",
        "    plt.title(f'Ultrasound Image {idx}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot Predicted Mask\n",
        "    plt.subplot(3, 3, 3*i + 2)\n",
        "    plt.imshow(predictions[idx], cmap='plasma')\n",
        "    plt.title(f'Predicted Mask {idx}')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Plot Actual Mask\n",
        "    plt.subplot(3, 3, 3*i + 3)\n",
        "    plt.imshow(testMasks[idx], cmap='plasma')\n",
        "    plt.title(f'Actual Mask {idx}')\n",
        "    plt.axis('off')\n",
        "\n",
        "# Adjust layout and show the figure\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:16:09.909097Z",
          "iopub.execute_input": "2024-08-12T18:16:09.910004Z",
          "iopub.status.idle": "2024-08-12T18:16:11.762541Z",
          "shell.execute_reply.started": "2024-08-12T18:16:09.90997Z",
          "shell.execute_reply": "2024-08-12T18:16:11.761602Z"
        },
        "trusted": true,
        "id": "CCxVaX6gQ7Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segmentationModel.save('Breast Cancer Segmentation.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T18:16:23.043328Z",
          "iopub.execute_input": "2024-08-12T18:16:23.043692Z",
          "iopub.status.idle": "2024-08-12T18:16:23.302735Z",
          "shell.execute_reply.started": "2024-08-12T18:16:23.043663Z",
          "shell.execute_reply": "2024-08-12T18:16:23.301885Z"
        },
        "trusted": true,
        "id": "Ugjs3ixeQ7Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1CV0DcHZQ7Lg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}