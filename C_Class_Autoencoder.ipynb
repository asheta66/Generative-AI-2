{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2jU0Ub0KuYLvUBu/cKNQw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/Generative-AI-2/blob/main/C_Class_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**"
      ],
      "metadata": {
        "id": "Onyav4nNX5pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Install latex\n",
        "# !sudo apt-get update -y\n",
        "# !sudo apt-get install -y texlive texlive-latex-extra texlive-fonts-recommended dvipng cm-super"
      ],
      "metadata": {
        "id": "gbBG6ojEcQKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y pandas tensorflow\n",
        "# !pip install pandas tensorflow\n",
        "# !pip install seaborn"
      ],
      "metadata": {
        "id": "Jbp4IrMOdoPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Function to get the size of the first image in the directory\n",
        "def get_image_size(data_dir):\n",
        "    # List all files in the directory\n",
        "    files = [f for f in os.listdir(data_dir) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "\n",
        "    # Check if there are any image files in the directory\n",
        "    if not files:\n",
        "        raise FileNotFoundError(\"No image files found in the directory.\")\n",
        "\n",
        "    # Load the first image to determine its size\n",
        "    first_image_path = os.path.join(data_dir, files[0])\n",
        "    with Image.open(first_image_path) as img:\n",
        "        return img.size  # Returns (width, height)\n",
        "\n",
        "# Set the directory for the data stored on Google Drive\n",
        "data_dir = '/content/drive/My Drive/BrainTumor/256x256'\n",
        "\n",
        "# Automatically determine image size\n",
        "try:\n",
        "    img_size = get_image_size(data_dir)\n",
        "    batch_size = 32\n",
        "    print(f\"Image size set to: {img_size}\")\n",
        "except FileNotFoundError as e:\n",
        "    print(e)\n",
        "\n",
        "# Set up data generators for training and validation with 20% validation split\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_generator = datagen.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='input', subset='training')\n",
        "val_generator = datagen.flow_from_directory(data_dir, target_size=img_size, batch_size=batch_size, class_mode='input', subset='validation')\n",
        "\n",
        "# Determine the number of classes from the data generator\n",
        "num_classes = len(train_generator.class_indices)\n",
        "\n",
        "print(\"\")\n",
        "# Display the names of the classes and the number of images in each class\n",
        "print(\"Class Names and Number of Images:\")\n",
        "print(\"\")\n",
        "for class_name, index in train_generator.class_indices.items():\n",
        "    num_images = len(os.listdir(os.path.join(data_dir, class_name)))\n",
        "    print(f\"{class_name}: {num_images} images\")\n",
        "print(\"\")\n"
      ],
      "metadata": {
        "id": "dJ4lacVqXwt8",
        "outputId": "62f78ce2-c291-4b9f-e658-021450383458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "No image files found in the directory.\n",
            "Found 2452 images belonging to 3 classes.\n",
            "Found 612 images belonging to 3 classes.\n",
            "\n",
            "Class Names and Number of Images:\n",
            "\n",
            "glioma: 1426 images\n",
            "meningioma: 708 images\n",
            "pituitary tumor: 930 images\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define the Autoencoder model structure**"
      ],
      "metadata": {
        "id": "HzUrMTfDX2Fd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qze3-dKsIY4x"
      },
      "outputs": [],
      "source": [
        "# Define the Autoencoder model structure\n",
        "input_img = Input(shape=(img_size[0], img_size[1], 3))\n",
        "\n",
        "# Encoder part\n",
        "x = Flatten()(input_img)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "encoded = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Decoder part\n",
        "x = Dense(128, activation='relu')(encoded)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(img_size[0] * img_size[1] * 3, activation='sigmoid')(x)\n",
        "decoded = Reshape((img_size[0], img_size[1], 3))(x)\n",
        "\n",
        "# Compile the Autoencoder model\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the Autoencoder model\n",
        "history = autoencoder.fit(train_generator, epochs=10, validation_data=val_generator)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the encoder part of the Autoencoder for feature extraction and  build a classifier**"
      ],
      "metadata": {
        "id": "O-BS2abd6Sic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Extract the encoder part of the Autoencoder for feature extraction\n",
        "encoder = Model(inputs=input_img, outputs=encoded)\n",
        "\n",
        "# Generate encoded features for training and validation data\n",
        "train_features = encoder.predict(train_generator)\n",
        "val_features = encoder.predict(val_generator)\n",
        "\n",
        "# Get the corresponding labels and encode them into integer format\n",
        "train_labels = train_generator.classes\n",
        "val_labels = val_generator.classes\n",
        "\n",
        "# Initialize and train the Decision Tree classifier\n",
        "decision_tree_classifier = DecisionTreeClassifier()\n",
        "decision_tree_classifier.fit(train_features, train_labels)\n",
        "\n",
        "# Evaluate the classifier using the training data\n",
        "train_predictions = decision_tree_classifier.predict(train_features)\n",
        "train_labels_original = train_labels  # No need to convert to one-hot encoding for decision tree\n",
        "\n",
        "# Evaluate the classifier using the validation data\n",
        "val_predictions = decision_tree_classifier.predict(val_features)\n",
        "val_labels_original = val_labels  # No need to convert to one-hot encoding for decision tree\n"
      ],
      "metadata": {
        "id": "Za72o_HD6Q-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Display Results**"
      ],
      "metadata": {
        "id": "gn-cyp1rX-m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display confusion matrices and classification reports\n",
        "conf_matrix_train = confusion_matrix(train_labels_original, train_predictions)\n",
        "conf_matrix_val = confusion_matrix(val_labels_original, val_predictions)\n",
        "\n",
        "plt.figure(figsize=(7, 4))\n",
        "\n",
        "# Plot training confusion matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(conf_matrix_train, annot=True, fmt=\"d\", cmap='Blues',\n",
        "            xticklabels=train_generator.class_indices.keys(),\n",
        "            yticklabels=train_generator.class_indices.keys(),\n",
        "            annot_kws={\"size\": 10, \"weight\": \"bold\"})  # Annotation properties\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Training Confusion Matrix')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels\n",
        "plt.yticks(rotation=45, ha='right')  # Rotate y-axis labels\n",
        "\n",
        "# Plot validation confusion matrix\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(conf_matrix_val, annot=True, fmt=\"d\", cmap='Blues',\n",
        "            xticklabels=val_generator.class_indices.keys(),\n",
        "            yticklabels=val_generator.class_indices.keys(),\n",
        "            annot_kws={\"size\": 10, \"weight\": \"bold\"})  # Annotation properties\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Validation Confusion Matrix')\n",
        "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels\n",
        "plt.yticks(rotation=45, ha='right')  # Rotate y-axis labels\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the figure to a file\n",
        "plt.savefig('/content/confusion_matrices.png')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qEJhDO2oa6Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate and print performance metrics for the training data\n",
        "train_accuracy = accuracy_score(train_labels_original, train_predictions)\n",
        "train_precision = precision_score(train_labels_original, train_predictions, average='weighted')\n",
        "train_recall = recall_score(train_labels_original, train_predictions, average='weighted')\n",
        "train_f1 = f1_score(train_labels_original, train_predictions, average='weighted')\n",
        "\n",
        "print(\"Training Metrics:\")\n",
        "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Precision: {train_precision:.4f}\")\n",
        "print(f\"Recall: {train_recall:.4f}\")\n",
        "print(f\"F1 Score: {train_f1:.4f}\")\n",
        "print()\n",
        "\n",
        "# Calculate and print performance metrics for the validation data\n",
        "val_accuracy = accuracy_score(val_labels_original, val_predictions)\n",
        "val_precision = precision_score(val_labels_original, val_predictions, average='weighted')\n",
        "val_recall = recall_score(val_labels_\n"
      ],
      "metadata": {
        "id": "WggelMHp7aKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Training and Validation Loss for Autoencoder and Classifier Accuracy\n",
        "plt.figure(figsize=(8, 4))\n",
        "\n",
        "# Autoencoder Loss Curves\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Autoencoder Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Classifier Accuracy Curves\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_classifier.history['accuracy'], label='train_acc')\n",
        "plt.plot(history_classifier.history['val_accuracy'], label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Classifier Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UD00ltiwT6dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Plot 6 random images (1 from each class) in a 2x3 grid\n",
        "plt.figure(figsize=(6, 4))\n",
        "class_names = list(train_generator.class_indices.keys())\n",
        "num_samples_per_class = 1  # Select 1 random image per class\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    # Fetch a batch of images for the current class\n",
        "    class_images, _ = next(datagen.flow_from_directory(\n",
        "        data_dir,\n",
        "        target_size=img_size,\n",
        "        batch_size=100,  # Ensure batch size is large enough to include random images\n",
        "        class_mode='input',\n",
        "        subset='training',\n",
        "        shuffle=True,\n",
        "        classes=[class_name]\n",
        "    ))\n",
        "\n",
        "    # Select a random image from the batch\n",
        "    random_index = np.random.randint(0, class_images.shape[0])\n",
        "    image = class_images[random_index]\n",
        "\n",
        "    # Plot the random image\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.title(class_name)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n_0TJVVmayub"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}